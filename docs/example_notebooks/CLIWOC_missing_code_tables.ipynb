{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nutritional-indie",
   "metadata": {},
   "source": [
    "## Generating CLIWOC missing code tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grateful-coalition",
   "metadata": {},
   "source": [
    "The Climatological Database for the World's Oceans 1750-1850 ([CLIWOC](https://stvno.github.io/page/cliwoc/)) has valuable information on its supplemental data stored in the [IMMA](https://icoads.noaa.gov/e-doc/imma/R3.0-imma1.pdf) format under the C99 column.\n",
    "\n",
    "We have successfully extracted this information with the [mdf_reader()](https://git.noc.ac.uk/brecinosrivas/mdf_reader) tool, but several important variables are missing their code tables.\n",
    "\n",
    "List of variables:\n",
    "\n",
    "- Ship types\n",
    "- latitude indicator\n",
    "- longitude indicator,\n",
    "- air temperature units\n",
    "- sst units\n",
    "- air pressure units\n",
    "- units of attached thermometer\n",
    "- longitude units\n",
    "- Barometer type\n",
    "- Distance units\n",
    "- Distance units to land marks\n",
    "- Distance units of how much the ship traveled\n",
    "- Units of other measurements (e.g. current speed)\n",
    "- Humidity units\n",
    "\n",
    "According to the [documentation](https://stvno.github.io/page/cliwoc/) of this deck (730) there are up to 20 different ways of writing down the air pressure but the code tables are not available anymore on the website. Therefore, we extracted from the supplemental data all possible entries for those fields which are missing a code table. We count each entry in order to construct a code table for that particular variable.\n",
    "\n",
    "The code to extract multiple variables from the CLIWOC supplemental data can be found [here](https://git.noc.ac.uk/brecinosrivas/mdf_reader/-/blob/master/tests/gather_stats_c99.py)\n",
    "\n",
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# PARAMS for plots\n",
    "from matplotlib import rcParams\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "rcParams[\"axes.labelsize\"] = 14\n",
    "rcParams[\"xtick.labelsize\"] = 14\n",
    "rcParams[\"ytick.labelsize\"] = 14\n",
    "rcParams[\"legend.fontsize\"] = 16\n",
    "rcParams[\"legend.title_fontsize\"] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-ferry",
   "metadata": {},
   "source": [
    "We stored the statistics per year in python pickle dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to data\n",
    "dirs = \"/Users/brivas/c3s_work/mdf_reader/tests/data/133-730/133-730\"\n",
    "file_names = sorted(os.listdir(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(dic, key, year):\n",
    "    \"\"\"\n",
    "    Get individual sets of values from the pickle df\n",
    "    Params:\n",
    "    ------\n",
    "    dic: python dictionary containing all variables stats per year\n",
    "    key: variable name\n",
    "    year: year to extract\n",
    "    Returns:\n",
    "    --------\n",
    "    indexes: these are the variable types (e.g. barque or nan)\n",
    "    series.values: these are the counts of how many that variable name gets repeated\n",
    "    year: year to sample\n",
    "    \"\"\"\n",
    "    series = dic[key]\n",
    "    indexes = series.index.values\n",
    "    year = np.repeat(year, len(indexes))\n",
    "    return indexes, series.values, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exptract_year_arrays(path_to_file, key):\n",
    "    \"\"\"\n",
    "    Reads pickle file and extracts the variable arrays per year\n",
    "    Parms:\n",
    "    -----\n",
    "    path_to_file: path to the pickle file\n",
    "    key: variable to extract\n",
    "    Returns:\n",
    "    --------\n",
    "    df: dataframe from get_df\n",
    "\n",
    "    \"\"\"\n",
    "    with open(path_to_file, \"rb\") as handle:\n",
    "        base = os.path.basename(path_to_file)\n",
    "        year = os.path.splitext(base)[0]\n",
    "        dic_pickle = pickle.load(handle)\n",
    "        df = get_values(dic_pickle, key, year)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_frame(list_of_files, main_directory, key):\n",
    "    # Define empty arrays to store the data\n",
    "    years = np.array([])\n",
    "    types_of_var = np.array([])\n",
    "    counts_var = np.array([])\n",
    "\n",
    "    for file in list_of_files:\n",
    "        full_path = os.path.join(main_directory, file)\n",
    "        var_type, count, year_f = exptract_year_arrays(full_path, key)\n",
    "        years = np.concatenate([years, year_f])\n",
    "        types_of_var = np.concatenate([types_of_var, var_type])\n",
    "        counts_var = np.concatenate([counts_var, count])\n",
    "\n",
    "    dataset = pd.DataFrame({\"Year\": years, key: types_of_var, \"Count\": counts_var})\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-jacob",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables names stored in the pickle files\n",
    "dic_keys = [\n",
    "    \"ship_types\",\n",
    "    \"lan_inds\",  # in a silly mistake I wrote lat wrong in the output data set. Oh well\n",
    "    \"lon_inds\",\n",
    "    \"at_units\",\n",
    "    \"sst_units\",\n",
    "    \"ap_units\",\n",
    "    \"bart_units\",\n",
    "    \"lon_units\",\n",
    "    \"baro_types\",\n",
    "    \"distance_units\",\n",
    "    \"distance_units_to_land\",\n",
    "    \"distance_units_travelled\",\n",
    "    \"units_of_other_measurements\",\n",
    "    \"humidity_units\",\n",
    "]\n",
    "\n",
    "\n",
    "df_ships = make_data_frame(file_names, dirs, dic_keys[0]).dropna()\n",
    "df_lati = make_data_frame(file_names, dirs, dic_keys[1]).dropna()\n",
    "df_loni = make_data_frame(file_names, dirs, dic_keys[2]).dropna()\n",
    "df_atu = make_data_frame(file_names, dirs, dic_keys[3]).dropna()\n",
    "df_sstu = make_data_frame(file_names, dirs, dic_keys[4]).dropna()\n",
    "df_apu = make_data_frame(file_names, dirs, dic_keys[5]).dropna()\n",
    "df_bartu = make_data_frame(file_names, dirs, dic_keys[6]).dropna()\n",
    "df_lonu = make_data_frame(file_names, dirs, dic_keys[7]).dropna()\n",
    "df_barot = make_data_frame(file_names, dirs, dic_keys[8]).dropna()\n",
    "\n",
    "df_distu = make_data_frame(file_names, dirs, dic_keys[9]).dropna()\n",
    "df_distu_land = make_data_frame(file_names, dirs, dic_keys[10]).dropna()\n",
    "df_distu_travel = make_data_frame(file_names, dirs, dic_keys[11]).dropna()\n",
    "df_unit_m = make_data_frame(file_names, dirs, dic_keys[12]).dropna()\n",
    "df_humi_u = make_data_frame(file_names, dirs, dic_keys[13]).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-discovery",
   "metadata": {},
   "source": [
    "- Ship types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "types_of_ships = df_ships.ship_types.unique()\n",
    "types_of_ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(types_of_ships)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-macintosh",
   "metadata": {},
   "source": [
    "Now we subdivide `ship_types` into groups that represent the types of sailing/steam ships or into a general category **sailing ship**; which covers all the different translations of the word ship in all languages of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-crawford",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"Types of Ship\": types_of_ships})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-secondary",
   "metadata": {},
   "source": [
    "Bark or Barque can also be refer as barc (e.g Falucho in [catalan](https://es.wikipedia.org/wiki/Barca_levantina))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bark_or_Barque = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"BARK\", \"FALUCHO\"]))]\n",
    "Bark_or_Barque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-coaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "Barkentine_or_Barquentine = df[\n",
    "    df[\"Types of Ship\"].str.contains(\"|\".join([\"BARQUEN\", \"BARKEN\"]))\n",
    "]\n",
    "Barkentine_or_Barquentine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-migration",
   "metadata": {},
   "source": [
    "Brigantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brigantine = df[\n",
    "    df[\"Types of Ship\"].str.contains(\n",
    "        \"|\".join([\"BRIG\", \"BRIGAN\", \"BRIK\", \"BERGANTIN\", \"BRICK\", \"BARGENTIJN\"])\n",
    "    )\n",
    "]\n",
    "Brigantine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-reviewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "Schooner = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"SCHO\", \"GOLET\"]))]\n",
    "Schooner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "Frigate = df[df[\"Types of Ship\"].str.contains(\"GAT\", regex=False)]\n",
    "Frigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "Steam = df[df[\"Types of Ship\"].str.contains(\"STEAM\", regex=False)]\n",
    "Steam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "Corvet = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"KORV\", \"CORVE\"]))]\n",
    "Corvet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cotter = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"KOTT\", \"COTT\", \"CUTT\"]))]\n",
    "Cotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sloop = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"SLOOP\", \"SLOEP\"]))]\n",
    "Sloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "Snow = df[df[\"Types of Ship\"].str.contains(\"|\".join([\"SNOW\", \"SNA\"]))]\n",
    "Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-trading",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naval_salining_ships = df[\n",
    "    df[\"Types of Ship\"].str.contains(\"|\".join([\"TH RATE\", \"AVISO\", \"RATE\"]))\n",
    "]\n",
    "Naval_salining_ships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "East_Indianman = df[df[\"Types of Ship\"].str.contains(\"SPIEGELRETOURSC\")]\n",
    "East_Indianman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-template",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scow = df[df[\"Types of Ship\"].str.contains(\"GABARRE\")]\n",
    "Scow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fluyt = df[df[\"Types of Ship\"].str.contains(\"FLU\")]\n",
    "Fluyt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ships_all_languages = df[\n",
    "    df[\"Types of Ship\"].str.contains(\n",
    "        \"|\".join(\n",
    "            [\n",
    "                \"SHIP\",\n",
    "                \"PAQUE\",\n",
    "                \"PAKKET\",\n",
    "                \"BUQUE\",\n",
    "                \"VES\",\n",
    "                \"SCHIP\",\n",
    "                \"NAV\",\n",
    "                \"TRANSP\",\n",
    "                \"EXPLOR\",\n",
    "                \"CHAMBE\",\n",
    "                \"BALANDRA\",\n",
    "                \"PINK\",\n",
    "                \"HOEKER\",\n",
    "                \"POLACRA\",\n",
    "                \"KOOP\",\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "]\n",
    "Ships_all_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-butterfly",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = (\n",
    "    len(Bark_or_Barque)\n",
    "    + len(Barkentine_or_Barquentine)\n",
    "    + len(Brigantine)\n",
    "    + len(Schooner)\n",
    "    + len(Frigate)\n",
    "    + len(Steam)\n",
    "    + len(Corvet)\n",
    "    + len(Cotter)\n",
    "    + len(Sloop)\n",
    "    + len(Snow)\n",
    "    + len(Ships_all_languages)\n",
    "    + len(East_Indianman)\n",
    "    + len(Scow)\n",
    "    + len(Fluyt)\n",
    ")\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-transition",
   "metadata": {},
   "source": [
    "There are about 9 sub types that are hard to classify and more research is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-syndicate",
   "metadata": {},
   "source": [
    "- AT units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atu.at_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unnecessary-binary",
   "metadata": {},
   "source": [
    "- SST units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sstu.sst_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-rings",
   "metadata": {},
   "source": [
    "- Air pressure units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_apu.ap_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-apollo",
   "metadata": {},
   "source": [
    "The **DLS** unit format is believed to stand for Dutch Lines and the 12R or 10R means that were reduced to 12 or 10 Réaumur (like pressures reduced to 32F). This is still an ongoing discussion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-bulgarian",
   "metadata": {},
   "source": [
    "- Attached thermometer units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bartu.bart_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-shelf",
   "metadata": {},
   "source": [
    "- Longitude Units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lonu.lon_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-appreciation",
   "metadata": {},
   "source": [
    "- Barometer types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatty-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_barot.baro_types.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-pressure",
   "metadata": {},
   "source": [
    "- Other units for which there was no information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distu_land.distance_units_to_land.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "about-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distu_travel.distance_units_travelled.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unit_m.units_of_other_measurements.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_humi_u.humidity_units.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-antibody",
   "metadata": {},
   "source": [
    "An overview through time of some of the Barometer types and air pressure units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "g = sns.histplot(\n",
    "    data=df_barot,\n",
    "    x=\"Year\",\n",
    "    hue=\"baro_types\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"deep\",\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    ")\n",
    "ax.grid(False)\n",
    "plt.setp(g.get_xticklabels(), rotation=45)\n",
    "plt.title(\"Barometer types\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "cmap = sns.set_palette(\"rocket\", n_colors=len(df_apu.ap_units.unique()))\n",
    "\n",
    "g = sns.histplot(\n",
    "    data=df_apu,\n",
    "    x=\"Year\",\n",
    "    hue=\"ap_units\",\n",
    "    multiple=\"stack\",\n",
    "    palette=cmap,\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    ")\n",
    "ax.grid(False)\n",
    "plt.setp(g.get_xticklabels(), rotation=45)\n",
    "plt.title(\"Air temp units\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-paste",
   "metadata": {},
   "source": [
    "**Overview of the position quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-international",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "\n",
    "g = sns.histplot(\n",
    "    data=df_lati,\n",
    "    x=\"Year\",\n",
    "    hue=\"lan_inds\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"deep\",\n",
    "    ax=ax[0],\n",
    "    legend=True,\n",
    ")\n",
    "plt.setp(g.get_xticklabels(), rotation=45)\n",
    "ax[0].grid(False)\n",
    "\n",
    "xticks = ax[0].xaxis.get_major_ticks()\n",
    "for i in range(len(xticks)):\n",
    "    if i % 2 == 1:\n",
    "        xticks[i].set_visible(False)\n",
    "\n",
    "ax[0].set_title(\n",
    "    \"Coordinates indicator\", fontdict={\"fontsize\": 16, \"fontweight\": \"medium\"}\n",
    ")\n",
    "ax[0].set_xlabel(\"\")\n",
    "\n",
    "\n",
    "p = sns.histplot(\n",
    "    data=df_loni,\n",
    "    x=\"Year\",\n",
    "    hue=\"lon_inds\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"colorblind\",\n",
    "    ax=ax[1],\n",
    "    legend=True,\n",
    ")\n",
    "plt.setp(p.get_xticklabels(), rotation=45)\n",
    "ax[1].grid(False)\n",
    "\n",
    "xticks = ax[1].xaxis.get_major_ticks()\n",
    "for i in range(len(xticks)):\n",
    "    if i % 2 == 1:\n",
    "        xticks[i].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-victim",
   "metadata": {},
   "source": [
    "Code table for lat and lon indicators, according to this [information](https://stvno.github.io/page/cliwoc/):\n",
    "\n",
    "```\n",
    "{\n",
    "\t\"1\":\"originates from dead reckoning\",\n",
    "\t\"2\":\"originates from true navigation (bearing/distance, celestial)\",\n",
    "\t\"3\":\"Interpolated manually\",\n",
    "\t\"4\":\"Interpolated\",\n",
    "\t\"5\":\"Inserted actual position (ports, islands, etc.)\",\n",
    "\t\"6\":\"Missing\"\n",
    "}\n",
    "```\n",
    "\n",
    "Is it worth using the coordinates from the supplemental metadata or should I use the imma.core lat and lon?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
